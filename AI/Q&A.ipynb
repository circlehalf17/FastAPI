{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"vzyNE3_0Kep7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743147753393,"user_tz":-540,"elapsed":5467,"user":{"displayName":"이원빈","userId":"01980967024098412535"}},"outputId":"c1e6b065-621f-4a8e-c6d6-935062db62b7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting faiss-cpu\n","  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n","Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n","Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: faiss-cpu\n","Successfully installed faiss-cpu-1.10.0\n"]}],"source":["!pip install faiss-cpu"]},{"cell_type":"code","source":["!pip install sentence-transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"XSFZbV3DyLni","executionInfo":{"status":"ok","timestamp":1743149281495,"user_tz":-540,"elapsed":146532,"user":{"displayName":"이원빈","userId":"01980967024098412535"}},"outputId":"201b82c3-d9be-476b-e0c7-66aee2a636c0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n","Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.50.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.14.1)\n","Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.29.3)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["nvidia"]},"id":"7907df22a7ba438093eb164debb23c1f"}},"metadata":{}}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3hKK0f_8Ikym"},"outputs":[],"source":["import faiss\n","import numpy as np\n","\n","def create_faiss_index(embeddings):\n","    \"\"\"\n","    코사인 유사도용 FAISS 인덱스를 생성하는 함수\n","\n","    Args:\n","        embeddings (np.ndarray): 임베딩 벡터 (2D 배열)\n","\n","    Returns:\n","        index (faiss.IndexFlatIP): FAISS 인덱스\n","    \"\"\"\n","    # 벡터 정규화 (코사인 유사도 계산을 위한 과정)\n","    faiss.normalize_L2(embeddings)\n","\n","    # 내적(Inner Product) 기반 인덱스 생성 (코사인 유사도 계산 가능)\n","    dimension = embeddings.shape[1]\n","    index = faiss.IndexFlatIP(dimension)\n","\n","    # 인덱스에 임베딩 추가\n","    index.add(embeddings)\n","\n","    return index"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HVSdQ3SsLERl"},"outputs":[],"source":["from transformers import BertTokenizer, BertModel\n","import torch\n","\n","# BERT 모델 및 토크나이저 로드\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","model = BertModel.from_pretrained('bert-base-uncased')\n","\n","# BERT 모델 저장\n","model.save_pretrained(\"./bert_model\")\n","tokenizer.save_pretrained(\"./bert_model\")\n","\n","def get_bert_embedding(text):\n","    \"\"\"\n","    BERT 임베딩 생성 함수\n","\n","    Args:\n","        text (str): 임베딩할 텍스트\n","\n","    Returns:\n","        embedding (np.ndarray): 임베딩 벡터 (1D 배열)\n","    \"\"\"\n","    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n","    outputs = model(**inputs)\n","\n","    # [CLS] 토큰의 임베딩 사용 (문장 전체 의미 표현)\n","    embedding = outputs.last_hidden_state[:, 0, :].detach().numpy()\n","\n","    return embedding.astype('float32')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r_RDyVRfvV7b"},"outputs":[],"source":["from transformers import AutoModelForCausalLM, AutoTokenizer\n","\n","# GPT-neo 로드\n","gpt_tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n","gpt_tokenizer.pad_token = gpt_tokenizer.eos_token\n","gpt_model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n","\n","# GPT-Neo 모델 저장\n","gpt_model.save_pretrained(\"./gpt_neo_model\")\n","gpt_tokenizer.save_pretrained(\"./gpt_neo_model\")\n","\n","def generate_gpt_response(context, question):\n","    \"\"\"\n","    GPT-neo로 Q&A 응답 생성\n","\n","    Args:\n","        context (str): Q&A 검색 결과로 얻은 문맥\n","        question (str): 사용자 질문\n","\n","    Returns:\n","        response (str): GPT-neo 응답 결과\n","    \"\"\"\n","    prompt = (\"다음은 Q&A 자동응답 시스템의 문맥과 질문입니다. 문맥을 바탕으로 질문에 답하세요.\\n\\n\"f\"문맥: {context}\\n질문: {question}\\n답변: \")\n","    inputs = gpt_tokenizer(prompt, return_tensors='pt', max_length=1024, truncation=True)\n","    outputs = gpt_model.generate(inputs.input_ids, max_length=1024, num_return_sequences=1, early_stopping=True, pad_token_id=gpt_tokenizer.eos_token_id)\n","\n","    response = gpt_tokenizer.decode(outputs[0], skip_special_tokens=True).split(\"답변:\")[-1].strip()\n","    return response"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BwYAJQ6uvtbZ"},"outputs":[],"source":["def qa_pipeline(question, index, embeddings, qa_texts, k=5):\n","    \"\"\"\n","    Q&A 자동응답 시스템 파이프라인\n","\n","    Args:\n","        question (str): 사용자 질문\n","        index (faiss.IndexFlatIP): FAISS 인덱스\n","        embeddings (np.ndarray): 기존 Q&A 임베딩 벡터\n","        qa_texts (list): 기존 Q&A 텍스트 리스트\n","        k (int): 상위 몇 개의 유사 Q&A를 가져올지\n","\n","    Returns:\n","        gpt_response (str): GPT-neo로 생성한 응답\n","    \"\"\"\n","\n","    # 1. 질문 임베딩 생성\n","    query_vector = get_bert_embedding(question)\n","\n","    # 2. 벡터 정규화 (코사인 유사도 계산)\n","    faiss.normalize_L2(query_vector)\n","    print(\"[query_vector]\")\n","    print(query_vector)\n","    # 3. FAISS 검색 (상위 k개 결과 반환)\n","    distances, indices = index.search(query_vector, k)\n","    print(\"[distances]\")\n","    print(distances)\n","    print(\"[indices]\")\n","    print(indices)\n","    # 4. 가장 유사한 Q&A 항목들 추출\n","    similar_texts = [qa_texts[i] for i in indices[0]]\n","    print(\"[similar_texts]\")\n","    print(similar_texts)\n","    # 5. GPT-neo에게 문맥과 질문 제공, 응답 생성\n","    context = \" \".join(similar_texts)\n","    gpt_response = generate_gpt_response(context, question)\n","\n","    return gpt_response"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HlRVkJM53Ag7","outputId":"35fb6755-f4d9-4e94-e095-0163c5022493","executionInfo":{"status":"ok","timestamp":1743153689854,"user_tz":-540,"elapsed":324234,"user":{"displayName":"이원빈","userId":"01980967024098412535"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[embeddings]\n","[[-0.50681555 -0.2028872  -0.33815995 ...  0.01465861  0.81922936\n","  -0.09951616]\n"," [-0.43236676 -0.40407437 -0.19400476 ... -0.10309409  0.814261\n","  -0.03031765]\n"," [-0.5119181  -0.25768512 -0.33776063 ...  0.03305429  0.84757555\n","  -0.15074971]\n"," [-0.50990474 -0.33507633 -0.01816359 ... -0.11603286  0.90274453\n","  -0.06597818]\n"," [-0.47904012 -0.26681828 -0.43792173 ...  0.07808858  0.86179936\n","   0.00239504]]\n","[index]\n","<faiss.swigfaiss_avx2.IndexFlatIP; proxy of <Swig Object of type 'faiss::IndexFlatIP *' at 0x7a1ef623f5a0> >\n","[query_vector]\n","[[-2.83597279e-02 -9.33401659e-03 -2.93455683e-02 -2.23542117e-02\n","  -5.48630618e-02 -6.61463523e-03  6.62154257e-02  3.86597663e-02\n","   6.94077788e-03 -2.45053656e-02  8.23835551e-04 -2.14492599e-03\n","  -1.30842915e-02  1.74964208e-03  1.00416327e-02  1.06031699e-02\n","  -7.17888540e-03  1.72326677e-02  2.54053827e-02  1.66453831e-02\n","  -4.33237106e-02  1.72337436e-03 -7.24914437e-03 -4.71551670e-03\n","   8.59881379e-03 -3.20536904e-02 -1.29767526e-02  2.11535138e-03\n","   3.58618423e-02  5.13622817e-03  5.15490025e-03  1.96013618e-02\n","  -1.43199079e-02 -4.88076075e-05  4.05194946e-02  1.56493448e-02\n","  -1.85979698e-02  4.48972359e-03  4.13119467e-03  2.59542707e-02\n","   1.01874890e-02  1.38792079e-02  3.83794308e-02 -1.40529005e-02\n","   3.11255585e-02 -5.66470698e-02 -1.92370087e-01  4.07571457e-02\n","  -6.71035051e-02 -4.30780649e-02  2.75987498e-02  1.09906020e-02\n","   1.27865802e-02  2.37057265e-03 -4.01991904e-02  5.22130169e-02\n","  -1.82003602e-02  3.23790200e-02  3.58636305e-02  2.41466742e-02\n","  -1.33572109e-02  2.27192938e-02  9.61474329e-03 -1.99691057e-02\n","  -1.19370818e-02  2.77206041e-02 -3.33130471e-02  1.96087435e-02\n","  -2.76770461e-02  2.83868294e-02 -2.16474701e-02  2.43956205e-02\n","   2.79168207e-02  1.13731800e-02  5.00441715e-03 -1.92343388e-02\n","  -3.53998202e-03  4.28179599e-04 -4.28633653e-02  1.12301195e-02\n","   1.95526984e-02  2.88866088e-02  2.82718670e-02 -2.90579312e-02\n","   1.90734752e-02  3.73606756e-02 -2.84520518e-02 -5.63779920e-02\n","   1.43728871e-02  6.98116794e-03 -2.75499430e-02 -3.29375616e-03\n","  -1.21942069e-02  5.72899058e-02  1.53959477e-02  3.19017805e-02\n","  -1.54683497e-02  1.55485757e-02 -2.03315727e-02  2.61574928e-02\n","  -2.22361684e-02  1.37319006e-02  1.74796470e-02 -1.23063512e-02\n","  -1.92863785e-03 -5.44724278e-02 -3.46792825e-02 -7.07359402e-04\n","   2.06373427e-02 -1.49921671e-01  3.00389118e-02  3.47589515e-02\n","  -1.58220567e-02 -2.36129947e-02  5.95639013e-02  5.30099720e-02\n","   4.17574644e-02 -1.24024218e-02  6.17741905e-02  2.33511329e-02\n","   1.86342504e-02  5.14676701e-03 -4.78601269e-02  2.45678723e-02\n","  -9.24969744e-03  2.11780239e-02  2.99115200e-03 -2.81000752e-02\n","   1.23436796e-02  3.62913124e-02 -1.01320706e-02  6.43845350e-02\n","  -1.05830124e-02 -1.89736299e-02 -3.42280343e-02  1.08873583e-02\n","   4.50678691e-02  4.80901003e-02 -1.23491334e-02 -8.51193070e-03\n","  -6.05660155e-02 -2.11554579e-02 -1.53814942e-01 -1.31978246e-03\n","   5.61077483e-02 -1.31751318e-02 -3.91898677e-02 -2.74291839e-02\n","  -2.41166297e-02  5.17297722e-03 -1.33274775e-02 -1.93649884e-02\n","   8.77624098e-03  4.22319286e-02 -5.73616698e-02  3.36196125e-02\n","  -1.68024134e-02  1.79539546e-02 -1.80010498e-03  6.99010715e-02\n","  -1.13920867e-03 -2.19927751e-03 -2.88948398e-02 -8.91444832e-03\n","  -3.36047560e-02  9.88851395e-03 -2.18462199e-03  5.84235340e-02\n","  -3.50545044e-03 -7.94550311e-03 -1.10307867e-02 -2.06008125e-02\n","   2.32679248e-02  2.44900845e-02 -1.27633018e-02 -1.28753586e-02\n","  -8.34873319e-03  3.86286341e-02 -4.50035036e-02 -1.62259489e-03\n","  -2.44478174e-02  3.88837680e-02  2.75760656e-03 -4.70191017e-02\n","   1.64958611e-02  4.18537017e-03  1.73031222e-02 -1.74974091e-02\n","  -9.58416052e-03  7.01086223e-03 -2.14288756e-02 -1.06054787e-02\n","   6.03682885e-04  4.60776426e-02  3.92901748e-02  2.66932901e-02\n","   2.01918278e-02 -4.02125232e-02 -5.12053492e-03  3.35704312e-02\n","   2.32519861e-02 -1.03893327e-02  1.00730825e-02  2.49602413e-03\n","   5.85950445e-03  2.44294360e-01 -4.66041220e-03  4.33422299e-03\n","   2.42354944e-02 -8.92256430e-05  9.74709168e-04 -5.38525470e-02\n","   2.02450734e-02  1.03361299e-02 -3.97474971e-03 -5.57286069e-02\n","   5.42810522e-02 -6.58347690e-03 -2.56997608e-02  1.24289282e-02\n","   1.30406162e-02 -1.36169950e-02 -6.40576612e-03  3.45445611e-02\n","  -4.73888591e-02 -2.79280264e-02 -9.04698670e-03  2.13544648e-02\n","  -8.61067511e-03 -1.08994626e-01  2.63034720e-02 -1.63631067e-02\n","  -1.64647289e-02 -1.61163341e-02 -2.80157886e-02 -5.34239179e-03\n","  -1.92438345e-02 -5.36405891e-02  2.84872912e-02  7.21107936e-03\n","   9.37203586e-04  2.16917088e-03 -6.22011907e-03  5.28095895e-03\n","  -1.91014893e-02  2.35159532e-03 -4.36547538e-03 -4.03893068e-02\n","   2.46309247e-02 -9.79757495e-03  8.56811646e-03 -2.04740651e-02\n","   1.24801807e-02 -3.50392312e-02 -2.00805571e-02  4.18666564e-03\n","  -2.87682172e-02 -3.19158174e-02 -2.84766499e-02 -6.04504310e-02\n","  -3.61852311e-02  5.21847105e-04  4.34232950e-02 -2.29460131e-02\n","  -2.25874856e-02 -7.69361854e-03  4.63840328e-02 -1.77720506e-02\n","   1.12736374e-02 -1.89593825e-02 -1.77185312e-02 -2.73695756e-02\n","  -1.48322610e-02 -1.77243531e-01 -4.51239990e-03  2.57343780e-02\n","   3.70646380e-02  4.31702808e-02 -5.71568906e-02 -3.34628150e-02\n","   3.25188711e-02  8.89631826e-03 -2.32910644e-03  2.79371869e-02\n","   2.69950870e-02  1.21127181e-02  8.34391918e-03 -3.96058746e-02\n","   3.13870795e-02  2.92455461e-02 -9.58733726e-03  3.04635037e-02\n","  -2.98454855e-02 -4.19547176e-03  9.48047917e-03 -1.64798088e-02\n","   9.55389254e-03 -3.23875953e-04  7.39395758e-03  2.11480781e-02\n","   1.68906637e-02  7.37439981e-03 -8.12662113e-03  6.38740603e-03\n","   1.48108397e-02  1.86798275e-02 -4.29763878e-03 -8.89905822e-03\n","  -2.73172706e-01 -1.79307666e-02 -2.71739680e-02 -8.64867680e-03\n","  -2.53516622e-03 -1.28042763e-02  5.11380844e-02 -2.44435146e-02\n","  -1.00047709e-02  8.70281272e-03 -1.88086983e-02 -9.99340881e-03\n","  -2.00989246e-02  1.42340241e-02 -1.36059953e-03  1.24783916e-02\n","   4.36456539e-02 -5.33254305e-03  1.41069833e-02  3.43910273e-04\n","  -1.18260756e-02 -1.50826098e-02  1.39416456e-02  1.40152061e-02\n","   2.16820221e-02  3.59631926e-02 -4.47561499e-03 -4.59295958e-02\n","   7.53413327e-03  9.43160616e-03  7.01572222e-04 -4.45032194e-02\n","  -1.18467985e-02 -4.16455455e-02 -2.20347177e-02 -4.41484749e-02\n","   1.43000493e-02  6.05174224e-04  3.39190476e-02  3.73321921e-02\n","   3.21556665e-02  2.13595666e-02 -1.90374348e-02  3.27153429e-02\n","   9.66629013e-03 -3.20879295e-02 -4.85475268e-03 -1.85340401e-02\n","   1.12140132e-02  3.30285430e-02 -1.45172235e-02  2.16063466e-02\n","   7.59868920e-02 -3.81933078e-02  2.38557234e-02 -1.34738721e-02\n","   2.93402001e-02  4.77999728e-03  2.05148361e-03  2.79395317e-05\n","   8.30776021e-02 -7.29042711e-03 -1.92357171e-02 -9.13273171e-03\n","   1.36279305e-02 -1.13669438e-02  2.94268802e-02 -5.81867360e-02\n","   1.40159782e-02 -2.93608988e-03 -1.92891657e-02  3.52858193e-02\n","   1.62334722e-02 -7.02902302e-02 -3.97133129e-03  3.49840410e-02\n","  -4.97552678e-02  1.64050534e-02  1.15430523e-02  1.02902518e-03\n","  -2.61365296e-03  2.00773180e-02  2.30929279e-03  4.66419794e-02\n","  -4.19841111e-02  6.63823821e-03  1.20468372e-02  3.47597674e-02\n","  -7.43844211e-02  3.12823169e-02 -1.60483625e-02  7.30027165e-03\n","  -8.83518427e-04  7.53074558e-03 -3.66747100e-03  2.34616501e-03\n","   4.34636511e-02 -5.06051965e-02  3.90001088e-02 -2.32135579e-02\n","  -1.13241952e-02 -2.05747131e-02 -1.36748608e-02  2.36334782e-02\n","  -6.79388409e-03 -1.21710692e-02 -3.06046680e-02  1.11314666e-03\n","   2.27214880e-02  1.42138302e-02  1.98806208e-02 -1.25026172e-02\n","   1.87809858e-02  5.01669683e-02  4.53164838e-02 -2.20505651e-02\n","  -1.13782762e-02  2.06311326e-03 -1.75524410e-02  2.29447782e-02\n","   4.26765997e-03  8.16513970e-03 -4.13919166e-02 -2.08718795e-03\n","  -9.27208923e-03  6.10845070e-03  1.19029926e-02 -3.67832882e-03\n","  -2.92979572e-02 -2.07971334e-02  1.93099100e-02 -3.81525755e-02\n","  -4.71053384e-02 -3.86890993e-02 -1.20772477e-02  1.22869469e-03\n","  -2.01783720e-02 -1.69239403e-03  3.63023542e-02  2.02220511e-02\n","   2.96394452e-02 -1.61578190e-02  1.40615664e-02  3.62832062e-02\n","  -1.30586168e-02  4.14884165e-02  7.57789239e-03  1.77099761e-02\n","  -2.84797065e-02  3.51845212e-02  2.62386966e-02 -3.72709073e-02\n","   1.95961562e-03 -4.39347215e-02 -6.55576726e-03 -1.62527617e-03\n","  -4.75847023e-03 -6.29031509e-02 -7.46208010e-03  1.74216516e-02\n","   2.86558997e-02  1.67956799e-02 -1.04861431e-01  1.95329152e-02\n","   3.51136513e-02 -2.78998651e-02  4.73170690e-02  1.31161036e-02\n","  -5.95528409e-02 -4.72978316e-03  1.85102336e-02 -9.58893914e-03\n","  -3.59336585e-02 -1.68375168e-02  6.75727194e-03 -1.76727362e-02\n","   3.75476144e-02 -9.89298616e-03  1.26126409e-02 -2.07434520e-02\n","  -2.38153860e-02 -1.15894875e-03  4.43359837e-03  7.99210183e-03\n","   1.86720565e-02 -3.51468325e-02  2.92998506e-03 -5.33832870e-02\n","  -1.12644993e-02  1.73430573e-02 -1.82968937e-02  5.31805679e-03\n","  -4.90322523e-03 -7.20790327e-02  9.87592060e-03 -2.81805582e-02\n","  -1.52042527e-02  1.74417421e-02  2.36338265e-02  1.90671291e-02\n","   2.85171270e-02  6.07537962e-02 -2.25594938e-02  1.70672443e-02\n","   2.23596375e-02 -1.88199384e-03  1.21817272e-02  2.44571697e-02\n","   1.26909595e-02  6.64461218e-03  1.64578967e-02 -5.24310991e-02\n","  -1.32903253e-04 -1.68386137e-03 -1.73269883e-02 -5.39682060e-03\n","   1.45031894e-02  4.39612719e-04 -6.87262090e-03 -5.46874627e-02\n","  -3.27406488e-02 -6.78690756e-03 -2.38689850e-03 -5.25026349e-03\n","  -1.90916229e-02  8.34506378e-03 -5.06261289e-02 -3.67586166e-02\n","  -6.72258204e-03 -4.70546149e-02 -1.78993121e-02  4.64500710e-02\n","   5.51810898e-02  2.79501770e-02 -9.30229761e-03  1.35449860e-02\n","  -5.00924662e-02 -1.15050143e-02  1.97342467e-02  5.34845963e-02\n","   1.51385302e-02 -4.25884761e-02  4.49569896e-03 -3.91661264e-02\n","  -2.77135614e-02  3.94873098e-02 -2.08157562e-02  1.11569595e-02\n","   1.80034079e-02  4.72592888e-03 -1.44759584e-02 -1.29062301e-02\n","  -2.46833935e-02 -4.22473364e-02  4.49040346e-02 -1.93109624e-02\n","   1.69536099e-02  4.77488935e-02  8.63074046e-03  2.55359104e-03\n","  -2.25566979e-02  2.84771752e-02 -3.21625639e-03  1.52440947e-02\n","   3.07720564e-02  6.84922514e-03 -3.51540186e-02  1.42180324e-02\n","   3.63543555e-02  3.07074171e-02 -7.17885941e-02 -9.20543261e-03\n","   1.51066687e-02  4.39176336e-03 -3.79237160e-02 -2.19134279e-02\n","   5.95504651e-03 -1.59489531e-02 -2.63997763e-02 -2.50411611e-02\n","   1.21807694e-01  2.57839784e-02  4.06958163e-02  1.87035184e-02\n","   1.07891588e-02 -3.33075002e-02  2.15028990e-02 -3.32294442e-02\n","  -2.25451658e-03  6.14473084e-03 -4.05167118e-02 -4.70936578e-03\n","  -4.22222633e-03 -3.11763422e-03  1.84496455e-02  6.05344772e-02\n","   2.65590288e-03 -1.10188620e-02 -3.78103480e-02  2.46402044e-02\n","  -2.07792986e-02 -2.79770251e-02  1.11158406e-02 -1.05113424e-02\n","  -6.63305353e-03  4.12826575e-02  2.07759459e-02 -1.52265420e-02\n","  -2.26021353e-02  3.65680456e-02 -1.79656558e-02  9.60239954e-03\n","  -1.12032844e-02  3.51435095e-02 -2.03023106e-02 -2.01955880e-03\n","  -2.01899894e-02 -3.35082188e-02 -4.61936370e-02  2.38558631e-02\n","  -1.20503604e-02  5.94172580e-03  1.71663351e-02  3.50771956e-02\n","   2.33862679e-02  1.42812275e-03 -4.62833047e-03 -4.25124690e-02\n","  -1.15883686e-02  3.99429053e-02  1.26434874e-03 -1.64959896e-02\n","  -1.88877098e-02 -3.54312058e-03 -1.20951775e-02 -4.75990120e-03\n","   2.45642811e-02 -2.11912636e-02 -2.91601401e-02  5.45642972e-02\n","  -2.90908217e-02  1.17128333e-02  2.51932200e-02 -4.08221446e-02\n","  -1.01311756e-02 -1.08974651e-02  4.56429552e-03 -6.51632994e-03\n","  -2.12422777e-02 -5.60751464e-03 -4.67753876e-03  2.39435136e-02\n","   2.05126256e-02  5.19451052e-02  2.77173035e-02  8.49833433e-03\n","   1.11508311e-03 -2.76493821e-02  8.76196951e-04 -1.36778101e-01\n","   9.72021557e-03  3.96562554e-02 -4.83650248e-03 -4.55361791e-03\n","   7.47240940e-03  6.90514920e-03  1.08639374e-02  5.78003144e-03\n","   1.21993909e-03  2.04408355e-03  4.63564917e-02  2.75468845e-02\n","   2.64005829e-02  1.69770308e-02  1.84995532e-02  1.30657563e-02\n","  -1.89141911e-02 -1.65280942e-02 -1.21859089e-02 -6.47564232e-02\n","   2.12577488e-02 -1.06727351e-02  2.23710071e-02  7.62549229e-03\n","   4.69847359e-02  3.72158326e-02 -1.42107939e-03  2.76622865e-02\n","   4.25961392e-04 -7.34110223e-03  4.15456928e-02  2.10981071e-02\n","   2.30138618e-02 -2.58059753e-03  1.61573663e-02 -1.83974616e-02\n","   1.18670631e-02  2.18669455e-02  1.08704427e-02  4.31561237e-03\n","   6.27719015e-02  1.90708705e-03  1.63618568e-02 -4.99602221e-03\n","  -1.36783440e-02  3.38110141e-02 -2.04778779e-02  8.79878923e-02\n","  -5.47262207e-02 -2.90968362e-02 -7.21616158e-03 -1.42049650e-02\n","   1.96823068e-02 -1.80846127e-03  8.16549407e-04  2.80586388e-02\n","   2.08370723e-02 -1.64656285e-02 -3.89012732e-02 -2.30005737e-02\n","   1.57500990e-02 -3.03225555e-02 -2.56622356e-04  4.24462892e-02\n","  -3.04567162e-02 -1.25419572e-02  9.55533702e-03  4.52893451e-02\n","   4.10509901e-03 -2.78965337e-03  1.69978989e-03  1.83737967e-02\n","   4.20991480e-02 -1.53543279e-02  2.45497581e-02  4.52990048e-02\n","   7.90328905e-02  3.78297679e-02  5.34302089e-03 -9.57380515e-04\n","   2.65825819e-02 -2.25519063e-03  2.85979304e-02  3.23498547e-02\n","  -3.90054852e-01 -2.38922592e-02  2.26736031e-02 -9.22785420e-03\n","  -1.94878352e-03  1.96468215e-02  7.96975102e-03 -5.65353446e-02\n","  -4.08430258e-03 -1.71484612e-02  2.73107085e-03 -1.34563101e-02\n","  -9.93674900e-03  7.21049961e-03  4.87449877e-02 -1.48229795e-02]]\n","[distances]\n","[[0.968105   0.9647447  0.9608202  0.9305634  0.91570485]]\n","[indices]\n","[[2 4 0 3 1]]\n","[similar_texts]\n","['BERT는 자연어 이해를 위한 사전 훈련된 트랜스포머 모델입니다.', '코사인 유사도는 두 벡터의 방향성을 비교해 얼마나 유사한지 측정하는 지표입니다.', 'AI는 인공지능의 줄임말로, 기계가 사람처럼 학습하고 추론할 수 있도록 하는 기술입니다.', 'GPT-neo는 언어 생성을 위한 트랜스포머 모델로, 대규모 데이터를 바탕으로 훈련되었습니다.', 'FAISS는 Facebook AI에서 만든 고차원 벡터 검색 라이브러리입니다.']\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:676: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n","  warnings.warn(\n","The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"]},{"output_type":"stream","name":"stdout","text":["GPT-neo 응답: 기계가 사람처럼\n","\n","질문: 인공지능의 줄임말로, 기계가 사람처럼\n","�\n"]}],"source":["# 1. 기존 Q&A 데이터\n","qa_texts = [\n","    \"AI는 인공지능의 줄임말로, 기계가 사람처럼 학습하고 추론할 수 있도록 하는 기술입니다.\",\n","    \"FAISS는 Facebook AI에서 만든 고차원 벡터 검색 라이브러리입니다.\",\n","    \"BERT는 자연어 이해를 위한 사전 훈련된 트랜스포머 모델입니다.\",\n","    \"GPT-neo는 언어 생성을 위한 트랜스포머 모델로, 대규모 데이터를 바탕으로 훈련되었습니다.\",\n","    \"코사인 유사도는 두 벡터의 방향성을 비교해 얼마나 유사한지 측정하는 지표입니다.\"\n","]\n","\n","# 2. Q&A 임베딩 생성\n","embeddings = np.vstack([get_bert_embedding(text) for text in qa_texts])\n","print(\"[embeddings]\")\n","print(embeddings)\n","# 3. FAISS 인덱스 생성\n","index = create_faiss_index(embeddings)\n","print(\"[index]\")\n","print(index)\n","# 4. 질문 생성 및 응답 확인\n","question = \"인공지능의 줄임말로, 기계가 사람처럼\"\n","response = qa_pipeline(question, index, embeddings, qa_texts)\n","print(\"GPT-neo 응답:\", response)"]},{"cell_type":"code","source":["from sentence_transformers import SentenceTransformer\n","\n","# Sentence-BERT 모델 로드 (다양한 모델이 존재, 예시로 'paraphrase-MiniLM-L6-v2' 모델 사용)\n","model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n","\n","# 문장 리스트\n","sentences = [\n","    \"AI는 인공지능의 줄임말로, 기계가 사람처럼 학습하고 추론할 수 있도록 하는 기술입니다.\",\n","    \"FAISS는 Facebook AI에서 만든 고차원 벡터 검색 라이브러리입니다.\",\n","    \"BERT는 자연어 이해를 위한 사전 훈련된 트랜스포머 모델입니다.\",\n","    \"GPT-neo는 언어 생성을 위한 트랜스포머 모델로, 대규모 데이터를 바탕으로 훈련되었습니다.\",\n","    \"코사인 유사도는 두 벡터의 방향성을 비교해 얼마나 유사한지 측정하는 지표입니다.\"\n","]\n","\n","# 문장 임베딩 생성\n","embeddings = model.encode(sentences)\n","\n","# 임베딩 결과 출력 (각 문장에 대한 고차원 벡터)\n","for sentence, embedding in zip(sentences, embeddings):\n","    print(f\"Sentence: {sentence}\")\n","    print(f\"Embedding: {embedding[:5]}...\")  # 첫 5개 값만 출력\n","    print()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gebfYEVJ7A0s","executionInfo":{"status":"ok","timestamp":1743154060309,"user_tz":-540,"elapsed":1494,"user":{"displayName":"이원빈","userId":"01980967024098412535"}},"outputId":"326ab96a-4014-4f57-ff65-9744dd8fe985"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sentence: AI는 인공지능의 줄임말로, 기계가 사람처럼 학습하고 추론할 수 있도록 하는 기술입니다.\n","Embedding: [ 0.45696622  0.33455956 -0.02110084 -0.37054583 -0.01043585]...\n","\n","Sentence: FAISS는 Facebook AI에서 만든 고차원 벡터 검색 라이브러리입니다.\n","Embedding: [ 0.30969518 -0.1030289  -0.02162404 -0.39943364  0.17117104]...\n","\n","Sentence: BERT는 자연어 이해를 위한 사전 훈련된 트랜스포머 모델입니다.\n","Embedding: [ 0.00250799  0.1817315   0.12246078 -0.48240036 -0.05990716]...\n","\n","Sentence: GPT-neo는 언어 생성을 위한 트랜스포머 모델로, 대규모 데이터를 바탕으로 훈련되었습니다.\n","Embedding: [-0.00259389  0.06711136 -0.3267618  -0.50269693 -0.25174183]...\n","\n","Sentence: 코사인 유사도는 두 벡터의 방향성을 비교해 얼마나 유사한지 측정하는 지표입니다.\n","Embedding: [ 0.5120305   0.28432947  0.16044842 -0.20529318 -0.15759869]...\n","\n"]}]},{"cell_type":"code","source":["import faiss\n","import numpy as np\n","\n","# FAISS에서 사용할 임베딩 벡터 배열 (벡터를 L2 정규화)\n","embeddings = np.array(embeddings).astype(np.float32)\n","\n","# 벡터 정규화\n","faiss.normalize_L2(embeddings)\n","\n","# FAISS 인덱스 생성 (내적을 사용할 때는 IndexFlatIP를 사용)\n","index = faiss.IndexFlatIP(embeddings.shape[1])  # 임베딩 벡터의 차원\n","\n","# FAISS 인덱스에 임베딩 추가\n","index.add(embeddings)\n","\n","# 쿼리 문장\n","query_sentence = \"FAISS로 코사인 유사도를 계산한다는데 이게 무슨 말이야?\"\n","\n","# 쿼리 임베딩 생성\n","query_embedding = model.encode([query_sentence]).astype(np.float32)\n","\n","# 쿼리 벡터 정규화\n","faiss.normalize_L2(query_embedding)\n","\n","# 유사도 검색 (가장 유사한 3개 문장 검색)\n","distances, indices = index.search(query_embedding, 3)\n","\n","# 결과 출력\n","print(\"Query:\", query_sentence)\n","for i in range(3):\n","    print(f\"Top {i+1}: {sentences[indices[0][i]]} (Distance: {distances[0][i]:.4f})\")\n","\n","similar_texts = [sentences[i] for i in indices[0]]\n","print(similar_texts)\n","context = \" \".join(similar_texts)\n","gpt_response = generate_gpt_response(context, query_sentence)\n","print(gpt_response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tp41Cm3q86Do","executionInfo":{"status":"ok","timestamp":1743154496288,"user_tz":-540,"elapsed":404956,"user":{"displayName":"이원빈","userId":"01980967024098412535"}},"outputId":"03c5b193-affe-441a-ff89-02dc406f7af2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Query: FAISS로 코사인 유사도를 계산한다는데 이게 무슨 말이야?\n","Top 1: BERT는 자연어 이해를 위한 사전 훈련된 트랜스포머 모델입니다. (Distance: 0.8563)\n","Top 2: 코사인 유사도는 두 벡터의 방향성을 비교해 얼마나 유사한지 측정하는 지표입니다. (Distance: 0.8549)\n","Top 3: AI는 인공지능의 줄임말로, 기계가 사람처럼 학습하고 추론할 수 있도록 하는 기술입니다. (Distance: 0.8473)\n","['BERT는 자연어 이해를 위한 사전 훈련된 트랜스포머 모델입니다.', '코사인 유사도는 두 벡터의 방향성을 비교해 얼마나 유사한지 측정하는 지표입니다.', 'AI는 인공지능의 줄임말로, 기계가 사람처럼 학습하고 추론할 수 있도록 하는 기술입니다.']\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"mount_file_id":"1bVFXtQhlRGPf9nhxy4aFLQhcpoeCDgU-","authorship_tag":"ABX9TyPfGx7PjdhzZ+H1Ha7bL1jT"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}