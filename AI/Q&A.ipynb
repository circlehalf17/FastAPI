{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14964,"status":"ok","timestamp":1743487718905,"user":{"displayName":"이원빈","userId":"01980967024098412535"},"user_tz":-540},"id":"vzyNE3_0Kep7","outputId":"704b6e60-9a12-4f9e-8a32-04e8d5e8fa21"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.10.0)\n","Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n","Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n","Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.50.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.14.1)\n","Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.29.3)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.13.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.29.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.3.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.13.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n","Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (0.115.12)\n","Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (0.34.0)\n","Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (1.6.0)\n","Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.3)\n","Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (0.46.1)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi) (2.11.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (4.13.0)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (8.1.8)\n","Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.14.0)\n","Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.33.0)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.0)\n","Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi) (4.9.0)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (3.10)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (1.3.1)\n"]}],"source":["# 필요한 라이브러리 설치\n","!pip install faiss-cpu\n","!pip install sentence-transformers\n","!pip install transformers\n","!pip install fastapi uvicorn nest_asyncio pyngrok"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":50404,"status":"ok","timestamp":1743487769312,"user":{"displayName":"이원빈","userId":"01980967024098412535"},"user_tz":-540},"id":"3hKK0f_8Ikym","outputId":"e49fa52a-313d-4ddd-d2b9-10c6273bd0b4"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","Device set to use cuda:0\n"]}],"source":["# ================================\n","# 1. Sentence-BERT 임베딩\n","# ================================\n","from fastapi import FastAPI, Request\n","from pydantic import BaseModel\n","from typing import List\n","import numpy as np\n","import faiss\n","\n","from sentence_transformers import SentenceTransformer\n","from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n","\n","app = FastAPI()\n","\n","# Sentence-BERT 모델 로드\n","embedding_model = SentenceTransformer('all-MiniLM-L6-v2')  # 문장 임베딩 특화\n","\n","# GPT-Neo 모델 로드\n","gpt_model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n","gpt_tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n","gpt_tokenizer.pad_token = gpt_tokenizer.eos_token\n","qa_generator = pipeline(\"text-generation\", model=gpt_model, tokenizer=gpt_tokenizer)\n","\n","def get_bert_embedding(text):\n","    \"\"\"\n","    Sentence-BERT 기반 임베딩 생성\n","    \"\"\"\n","    embedding = embedding_model.encode([text], normalize_embeddings=True)  # 코사인 유사도용 정규화 포함\n","    return embedding.astype('float32')"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1743487769321,"user":{"displayName":"이원빈","userId":"01980967024098412535"},"user_tz":-540},"id":"HVSdQ3SsLERl"},"outputs":[],"source":["# ================================\n","# 2. FAISS 인덱스 생성\n","# ================================\n","def create_faiss_index(embeddings):\n","    \"\"\"\n","    FAISS 인덱스 생성 (코사인 유사도용 Inner Product)\n","    \"\"\"\n","    dim = embeddings.shape[1]\n","    index = faiss.IndexFlatIP(dim)\n","    index.add(embeddings)\n","    return index"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3946,"status":"ok","timestamp":1743487773268,"user":{"displayName":"이원빈","userId":"01980967024098412535"},"user_tz":-540},"id":"r_RDyVRfvV7b","outputId":"911eebfb-e340-42cf-8ad6-fc2ace09859e"},"outputs":[{"output_type":"stream","name":"stderr","text":["Device set to use cuda:0\n"]}],"source":["# ================================\n","# 3. GPT-Neo 응답 생성 (Pipeline 사용)\n","# ================================\n","# GPT-Neo 로드\n","gpt_model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n","gpt_tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n","gpt_tokenizer.pad_token = gpt_tokenizer.eos_token  # pad token 설정\n","\n","# Pipeline 구성\n","qa_generator = pipeline(\"text-generation\", model=gpt_model, tokenizer=gpt_tokenizer)\n","\n","def generate_gpt_response(context, question):\n","    \"\"\"\n","    GPT-Neo를 사용한 답변 생성\n","    \"\"\"\n","    prompt = f\"문맥: {context}\\n질문: {question}\\n답변:\"\n","    response = qa_generator(\n","        prompt,\n","        max_length=500,\n","        temperature=0.7,\n","        top_p=0.9,\n","        repetition_penalty=1.2,\n","        num_return_sequences=1,\n","        pad_token_id=gpt_tokenizer.eos_token_id\n","        )\n","    answer = response[0]['generated_text'].split(\"답변:\")[-1].strip()\n","    return answer"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":1237,"status":"ok","timestamp":1743487774520,"user":{"displayName":"이원빈","userId":"01980967024098412535"},"user_tz":-540},"id":"4qgaNdLyAhBr"},"outputs":[],"source":["# Q&A 데이터셋\n","qa_texts = [\n","    \"AI stands for Artificial Intelligence, which refers to technologies that enable machines to learn and reason like humans.\",\n","    \"FAISS is a high-dimensional vector search library developed by Facebook AI.\",\n","    \"BERT is a pre-trained transformer model designed for natural language understanding.\",\n","    \"GPT-Neo is a transformer-based language generation model trained on large-scale data.\",\n","    \"Cosine similarity is a metric that measures how similar two vectors are based on their direction.\"\n","]\n","\n","embeddings = np.vstack([get_bert_embedding(text) for text in qa_texts])\n","index = create_faiss_index(embeddings)\n","\n","# --------------------------\n","# 입력/출력 모델 정의\n","# --------------------------\n","class QARequest(BaseModel):\n","    question: str\n","    top_k: int = 3\n","\n","class QAResponse(BaseModel):\n","    question: str\n","    response: str\n","    context: List[str]\n","\n","# --------------------------\n","# FastAPI 라우터\n","# --------------------------\n","@app.post(\"/qa\", response_model=QAResponse)\n","def qa_endpoint(request: QARequest):\n","    question = request.question\n","    top_k = request.top_k\n","\n","    # 질문 임베딩\n","    query_vec = get_bert_embedding(question)\n","    distances, indices = index.search(query_vec, top_k)\n","\n","    # 유사 문맥 추출\n","    similar_texts = [qa_texts[i] for i in indices[0]]\n","    context = \" \".join(similar_texts)\n","\n","    # GPT 응답 생성\n","    gpt_response = generate_gpt_response(context, question)\n","\n","    return QAResponse(\n","        question=question,\n","        response=gpt_response,\n","        context=similar_texts\n","    )"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IUjGd0W_DUhL","executionInfo":{"status":"ok","timestamp":1743488059191,"user_tz":-540,"elapsed":284667,"user":{"displayName":"이원빈","userId":"01980967024098412535"}},"outputId":"fa49aeec-0dd8-4137-8ad3-f76eaaa1eed1"},"outputs":[{"output_type":"stream","name":"stdout","text":["🔗 Public URL: https://006c-34-82-40-125.ngrok-free.app\n"]},{"output_type":"stream","name":"stderr","text":["INFO:     Started server process [6809]\n","INFO:     Waiting for application startup.\n","INFO:     Application startup complete.\n","INFO:     Uvicorn running on http://0.0.0.0:3000 (Press CTRL+C to quit)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:     155.230.85.158:0 - \"GET /docs HTTP/1.1\" 200 OK\n","INFO:     155.230.85.158:0 - \"GET /openapi.json HTTP/1.1\" 200 OK\n"]},{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:     155.230.85.158:0 - \"POST /qa HTTP/1.1\" 200 OK\n","INFO:     155.230.85.158:0 - \"POST /qa HTTP/1.1\" 200 OK\n"]},{"output_type":"stream","name":"stderr","text":["INFO:     Shutting down\n","INFO:     Waiting for application shutdown.\n","INFO:     Application shutdown complete.\n","INFO:     Finished server process [6809]\n"]}],"source":["# 2. ngrok 실행 코드\n","from pyngrok import ngrok\n","import nest_asyncio\n","import uvicorn\n","\n","# 3. ngrok 설정\n","ngrok.set_auth_token(\"2v1Fi5CEzLumREBpheNMIIepRlM_7uLFbq5PGe81hmEZiAe9K\")  # 🔑 Ngrok 토큰 입력 (한 번만 필요)\n","ngrok.kill()  # 이전 터널 종료\n","public_url = ngrok.connect(3000)  # 로컬 3000 포트를 외부에 노출\n","print(\"🔗 Public URL:\", public_url.public_url)\n","\n","# 4. 이벤트 루프 충돌 방지 (Colab 전용)\n","nest_asyncio.apply()\n","\n","# 5. uvicorn 실행\n","uvicorn.run(app, host=\"0.0.0.0\", port=3000)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BwYAJQ6uvtbZ"},"outputs":[],"source":["# ================================\n","# 4. Q&A 파이프라인\n","# ================================\n","def qa_pipeline(question, index, qa_texts, k=3):\n","    \"\"\"\n","    Q&A 시스템 전체 파이프라인\n","    \"\"\"\n","    # 1. 질문 임베딩\n","    query_vec = get_bert_embedding(question)\n","\n","    # 2. FAISS 검색\n","    distances, indices = index.search(query_vec, k)\n","\n","    # 3. 상위 k개의 유사 문장 추출\n","    similar_texts = [qa_texts[i] for i in indices[0]]\n","\n","    # 4. 문맥 조합\n","    context = \" \".join(similar_texts)\n","\n","    # 5. GPT로 응답 생성\n","    gpt_response = generate_gpt_response(context, question)\n","\n","    # 🔍 로그 출력\n","    print(\"📌 질문:\", question)\n","    print(\"🔎 검색된 문장:\")\n","    for i, text in enumerate(similar_texts, 1):\n","        print(f\"{i}. {text}\")\n","    print(\"🧠 GPT 응답:\", gpt_response)\n","\n","    return gpt_response"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":172503,"status":"ok","timestamp":1743430730343,"user":{"displayName":"이원빈","userId":"01980967024098412535"},"user_tz":-540},"id":"HlRVkJM53Ag7","outputId":"6b9ffbf9-7293-4038-e28d-f7d8c9a5b221"},"outputs":[{"name":"stderr","output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"name":"stdout","output_type":"stream","text":["📌 질문: 인공지능이 뭐야?\n","🔎 검색된 문장:\n","1. AI는 인공지능의 줄임말로, 기계가 사람처럼 학습하고 추론할 수 있도록 하는 기술입니다.\n","2. 코사인 유사도는 두 벡터의 방향성을 비교해 얼마나 유사한지 측정하는 지표입니다.\n","3. BERT는 자연어 이해를 위한 사전 훈련된 트랜스포머 모델입니다.\n","🧠 GPT 응답: 전투에 사물이 취약점에 따라 있다. 유사도 전투를 통해 해석한 반응한 훈련을 통해 그 전과 연기와 연기를 시작한 반응훈련을 써도 연결하여 이어야 합니다.\n","“전과 연�\n","response:  전투에 사물이 취약점에 따라 있다. 유사도 전투를 통해 해석한 반응한 훈련을 통해 그 전과 연기와 연기를 시작한 반응훈련을 써도 연결하여 이어야 합니다.\n","“전과 연�\n"]}],"source":["# ================================\n","# 5. 실행 테스트\n","# ================================\n","# Q&A 데이터셋\n","qa_texts = [\n","    \"AI는 인공지능의 줄임말로, 기계가 사람처럼 학습하고 추론할 수 있도록 하는 기술입니다.\",\n","    \"FAISS는 Facebook AI에서 만든 고차원 벡터 검색 라이브러리입니다.\",\n","    \"BERT는 자연어 이해를 위한 사전 훈련된 트랜스포머 모델입니다.\",\n","    \"GPT-neo는 언어 생성을 위한 트랜스포머 모델로, 대규모 데이터를 바탕으로 훈련되었습니다.\",\n","    \"코사인 유사도는 두 벡터의 방향성을 비교해 얼마나 유사한지 측정하는 지표입니다.\"\n","]\n","\n","# 문장 임베딩 벡터 생성\n","embeddings = np.vstack([get_bert_embedding(text) for text in qa_texts])\n","\n","# FAISS 인덱스 생성\n","index = create_faiss_index(embeddings)\n","\n","# 테스트 질문\n","question = \"인공지능이 뭐야?\"\n","\n","# 응답 생성\n","response = qa_pipeline(question, index, qa_texts)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"mount_file_id":"1bVFXtQhlRGPf9nhxy4aFLQhcpoeCDgU-","authorship_tag":"ABX9TyPqO1juQhBsqo4Bwa4GBfKh"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}